{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OzGrav_VItamin_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hagabbar/OzGrav_demo/blob/master/OzGrav_VItamin_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZhkkfbAep7Z",
        "colab_type": "text"
      },
      "source": [
        "This tutorial is based on the paper Bayesian Parameter Estimation using Conditional Variational Autoencoders for Gravitational-wave Astronomy (https://arxiv.org/abs/1909.06296)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdoMTkVPVL6E",
        "colab_type": "text"
      },
      "source": [
        "# Set-up\n",
        "\n",
        "<img src=\"http://blog.davidecoppola.com/wp-content/uploads/2016/11/GitHub-logo-header.png\" width=\"734\" height=\"244\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuUk9Uy6hFxl",
        "colab_type": "text"
      },
      "source": [
        "Clone the repository (this may take a minute or two)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHVnnfXANukP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hagabbar/OzGrav_demo.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prloM1DhhIKV",
        "colab_type": "text"
      },
      "source": [
        "Change directory into cloned repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tA7BWiUN1NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd OzGrav_demo/\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_x-tg9hhLvs",
        "colab_type": "text"
      },
      "source": [
        "Install required packages (this may take a few minutes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI04ILUsRgRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kEliRxOhTpY",
        "colab_type": "text"
      },
      "source": [
        "Import required packages for notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naVHRD3ugIol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from IPython.display import Image, display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ4Y1K-FGo7Z",
        "colab_type": "text"
      },
      "source": [
        "Make sure to enable GPU in Edit -> Notebook setting -> Hardware accelerator\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/FYzZ7.png\" width=\"494\" height=\"350\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtFV8KXBpnI1",
        "colab_type": "text"
      },
      "source": [
        "# Interactive: Running VItamin on your own\n",
        "\n",
        "In the Running VItamin section, you will be able to generate your own data and run your own neural network to produce GW posteriors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMXMU1DTWoep",
        "colab_type": "text"
      },
      "source": [
        "## Generate Bilby Posterior Test Samples\n",
        "\n",
        "In this section I provide the code to generate your own bilby GW posteriors and their associated GW waveforms.\n",
        "\n",
        "<img src=\"https://git.ligo.org/uploads/-/system/project/avatar/1846/bilby.jpg\" width=\"400\" height=\"400\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DHQHxuacdFi",
        "colab_type": "text"
      },
      "source": [
        "### Define bounds and default fixed values for source parameters and search\n",
        "\n",
        "Those model parameters not defined here will use the default model parameters defined in bilby (see https://lscsoft.docs.ligo.org/bilby/prior.html) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnTS76ZkjxM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source parameter values to use if chosen to be fixed\n",
        "fixed_vals = {'mass_1':50.0,\n",
        "        'mass_2':50.0,\n",
        "        'mc':None,\n",
        "        'geocent_time':0.0,\n",
        "        'phase':0.0,\n",
        "        'ra':1.375,\n",
        "        'dec':-1.2108,\n",
        "        'psi':0.0,\n",
        "        'theta_jn':0.0,\n",
        "        'luminosity_distance':2000.0,\n",
        "        'a_1':0.0,\n",
        "        'a_2':0.0,\n",
        "\t'tilt_1':0.0,\n",
        "\t'tilt_2':0.0,\n",
        "        'phi_12':0.0,\n",
        "        'phi_jl':0.0,\n",
        "        'det':['H1','L1','V1']}                                                 # feel free to edit this if more or less detectors wanted\n",
        "\n",
        "\n",
        "# Prior bounds on source parameters\n",
        "bounds = {'mass_1_min':35.0, 'mass_1_max':80.0,\n",
        "        'mass_2_min':35.0, 'mass_2_max':80.0,\n",
        "        'M_min':70.0, 'M_max':160.0,\n",
        "        'geocent_time_min':0.15,'geocent_time_max':0.35,\n",
        "        'phase_min':0.0, 'phase_max':2.0*np.pi,\n",
        "        'ra_min':0.0, 'ra_max':2.0*np.pi,\n",
        "        'dec_min':-0.5*np.pi, 'dec_max':0.5*np.pi,\n",
        "        'psi_min':0.0, 'psi_max':2.0*np.pi,\n",
        "        'theta_jn_min':0.0, 'theta_jn_max':np.pi,\n",
        "        'a_1_min':0.0, 'a_1_max':0.0,\n",
        "        'a_2_min':0.0, 'a_2_max':0.0,\n",
        "        'tilt_1_min':0.0, 'tilt_1_max':0.0,\n",
        "        'tilt_2_min':0.0, 'tilt_2_max':0.0,\n",
        "        'phi_12_min':0.0, 'phi_12_max':0.0,\n",
        "        'phi_jl_min':0.0, 'phi_jl_max':0.0,\n",
        "        'luminosity_distance_min':1000.0, 'luminosity_distance_max':3000.0}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3BnAAf8jyHw",
        "colab_type": "text"
      },
      "source": [
        "### Define run parameters\n",
        "\n",
        "Here is where the user may customize their run. The `Main tunable variables` section is where the user may change variables such as source parameters to infer `inf_pars`, number of filters in each layer of each network `n_filters`, latent space dimensions `z_dimension`, etc.\n",
        "\n",
        "This notebook is still a work in progress, so please bear with me if some of the options prove to be a bit inflexible. :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NaP1BzdwW5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################\n",
        "# Main tunable variables\n",
        "##########################\n",
        "ndata = 256                                                                     # sampling frequency\n",
        "rand_pars = ['mass_1','mass_2','luminosity_distance','geocent_time','ra','dec']                                   # parameters to randomize (those not listed here are fixed otherwise)\n",
        "inf_pars=['luminosity_distance','geocent_time','ra','dec']                     # parameters to infer\n",
        "batch_size = 64                                                                 # Number training samples shown to neural network per iteration\n",
        "weight_init = 'xavier'                                                         #[xavier,VarianceScaling,Orthogonal] # Network model weight initialization    \n",
        "n_modes=7                                                                      # number of modes in Gaussian mixture model (ideal 7, but may go higher/lower)\n",
        "initial_training_rate=1e-4                                                     # initial training rate for ADAM optimiser inference model (inverse reconstruction)\n",
        "batch_norm=True                                                                # if true, do batch normalization in all layers of neural network\n",
        "\n",
        "# FYI, each item in lists below correspond to each layer in networks (i.e. first item first layer)\n",
        "# pool size and pool stride should be same number in each layer\n",
        "n_filters_r1 = [33, 33]                                                        # number of convolutional filters to use in r1 network (must be divisible by 3)\n",
        "n_filters_r2 = [33, 33]                                                        # number of convolutional filters to use in r2 network (must be divisible by 3)\n",
        "n_filters_q = [33, 33]                                                         # number of convolutional filters to use in q network  (must be divisible by 3)\n",
        "filter_size_r1 = [7,7]                                                         # size of convolutional fitlers in r1 network\n",
        "filter_size_r2 = [7,7]                                                         # size of convolutional filters in r2 network\n",
        "filter_size_q = [7,7]                                                          # size of convolutional filters in q network\n",
        "drate = 0.5                                                                    # dropout rate to use in fully-connected layers\n",
        "maxpool_r1 = [1,2]                                                             # size of maxpooling to use in r1 network\n",
        "conv_strides_r1 = [1,1]                                                        # size of convolutional stride to use in r1 network\n",
        "pool_strides_r1 = [1,2]                                                        # size of max pool stride to use in r1 network\n",
        "maxpool_r2 = [1,2]                                                             # size of max pooling to use in r2 network\n",
        "conv_strides_r2 = [1,1]                                                        # size of convolutional stride in r2 network\n",
        "pool_strides_r2 = [1,2]                                                        # size of max pool stride in r2 network\n",
        "maxpool_q = [1,2]                                                              # size of max pooling to use in q network\n",
        "conv_strides_q = [1,1]                                                         # size of convolutional stride to use in q network\n",
        "pool_strides_q = [1,2]                                                         # size of max pool stride to use in q network\n",
        "n_fc = 2048                                                                      # Number of neurons in fully-connected layers\n",
        "z_dimension=100                                                                 # number of latent space dimensions of model \n",
        "n_weights_r1 = [n_fc,n_fc,n_fc]                                                     # number fully-connected layers of encoders and decoders in the r1 model (inverse reconstruction)\n",
        "n_weights_r2 = [n_fc,n_fc,n_fc]                                                     # number fully-connected layers of encoders and decoders in the r2 model (inverse reconstruction)\n",
        "n_weights_q = [n_fc,n_fc,n_fc]                                                      # number fully-connected layers of encoders and decoders q model\n",
        "##########################\n",
        "# Main tunable variables\n",
        "##########################\n",
        "\n",
        "#############################\n",
        "# optional tunable variables\n",
        "#############################\n",
        "run_label = 'ozgrav-demo_%ddet_%dpar_%dHz_run1' % (len(fixed_vals['det']),len(rand_pars),ndata) # label of run\n",
        "bilby_results_label = 'ozgrav-demo'                                             # label given to bilby results directory\n",
        "r = 2                                                                           # number (to the power of 2) of test samples to use for testing. r = 2 means you want to use 2^2 (i.e 4) test samples\n",
        "pe_test_num = 256                                                               # total number of test samples available to use in directory\n",
        "tot_dataset_size = int(1e5)                                                     # total number of training samples available to use\n",
        "tset_split = int(1e3)                                                           # number of training samples in each training data file\n",
        "save_interval = int(2e3)                                                        # number of iterations to save model and plot validation results corner plots\n",
        "ref_geocent_time=1126259642.5                                                   # reference gps time (not advised to change this)\n",
        "load_chunk_size = 1e5                                                           # Number of training samples to load in at a time.\n",
        "samplers=['vitamin','dynesty']                                                 # Bayesian samplers to use when comparing ML results (vitamin is ML approach) dynesty,ptemcee,cpnest,emcee\n",
        "\n",
        "# Directory variables\n",
        "plot_dir=\"results/%s\" % run_label  # output directory to save results plots\n",
        "train_set_dir='training_sets_%ddet_%dpar_%dHz/tset_tot-%d_split-%d' % (len(fixed_vals['det']),len(rand_pars),ndata,tot_dataset_size,tset_split) # location of training set\n",
        "test_set_dir='test_sets/%s/four_parameter_case/test_waveforms' % bilby_results_label                                                            # location of test set directory waveforms\n",
        "pe_dir='test_sets/%s/four_parameter_case/test' % bilby_results_label                                                                            # location of test set directory Bayesian PE samples\n",
        "#############################\n",
        "# optional tunable variables\n",
        "#############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG3Z6hk2dYA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Function for getting list of parameters that need to be fed into the models\n",
        "def get_params():\n",
        "\n",
        "    # Define dictionary to store values used in rest of code \n",
        "    params = dict(\n",
        "        make_corner_plots = True,                                               # if True, make corner plots\n",
        "        make_kl_plot = True,                                                    # If True, go through kl plotting function\n",
        "        make_pp_plot = True,                                                    # If True, go through pp plotting function\n",
        "        make_loss_plot = False,                                                 # If True, generate loss plot from previous plot data\n",
        "        Make_sky_plot=False,                                                    # If True, generate sky plots on corner plots\n",
        "        hyperparam_optim = False,                                               # optimize hyperparameters for model during training using gaussian process minimization\n",
        "        resume_training=False,                                                  # if True, resume training of a model from saved checkpoint\n",
        "        load_by_chunks = True,                                                  # if True, load training samples by a predefined chunk size rather than all at once\n",
        "        ramp = True,                                                            # if true, apply linear ramp to KL loss\n",
        "        print_values=True,                                                      # optionally print loss values every report interval\n",
        "        by_channel = True,                                                      # if True, do convolutions as seperate 1-D channels, if False, stack training samples as 2-D images (n_detectors,(duration*sampling_frequency))\n",
        "        load_plot_data=False,                                                   # Plotting data which has already been generated\n",
        "        doPE = True,                                                            # if True then do bilby PE when generating new testing samples (not advised to change this)\n",
        "        gpu_num=0,                                                              # gpu number run is running on\n",
        "        ndata = ndata,                                                          \n",
        "        run_label=run_label,                                                    \n",
        "        bilby_results_label=bilby_results_label,                                \n",
        "        tot_dataset_size = tot_dataset_size,                                    \n",
        "        tset_split = tset_split,                                                \n",
        "        plot_dir=plot_dir,\n",
        "\n",
        "        # Gaussian Process automated hyperparameter tunning variables\n",
        "        hyperparam_optim_stop = int(1.5e6),                                     # stopping iteration of hyperparameter optimizer per call (ideally 1.5 million) \n",
        "        hyperparam_n_call = 30,                                                 # number of hyperparameter optimization calls (ideally 30)\n",
        "        load_chunk_size = load_chunk_size,                                      \n",
        "        load_iteration = int((load_chunk_size * 25)/batch_size),                # How often to load another chunk of training samples\n",
        "        weight_init = weight_init,                                           \n",
        "        n_samples = 1000,                                                       # number of posterior samples to save per reconstruction upon inference (default 3000) \n",
        "        num_iterations=int(1e4)+1,                                              # total number of iterations before ending training of model\n",
        "        initial_training_rate=initial_training_rate,                         \n",
        "        batch_size=batch_size,                                                  \n",
        "        batch_norm=batch_norm,                                                  \n",
        "        report_interval=500,                                                    # interval at which to save objective function values and optionally print info during training\n",
        "        n_modes=n_modes,                                                     \n",
        "\n",
        "        # FYI, each item in lists below correspond to each layer in networks (i.e. first item first layer)\n",
        "        # pool size and pool stride should be same number in each layer\n",
        "        n_filters_r1 = n_filters_r1,                                         \n",
        "        n_filters_r2 = n_filters_r2,                                         \n",
        "        n_filters_q = n_filters_q,                                           \n",
        "        filter_size_r1 = filter_size_r1,                                     \n",
        "        filter_size_r2 = filter_size_r2,                                     \n",
        "        filter_size_q = filter_size_q,                                       \n",
        "        drate = drate,                                                       \n",
        "        maxpool_r1 = maxpool_r1,                                             \n",
        "        conv_strides_r1 = conv_strides_r1,                                   \n",
        "        pool_strides_r1 = pool_strides_r1,                                   \n",
        "        maxpool_r2 = maxpool_r2,                                             \n",
        "        conv_strides_r2 = conv_strides_r2,                                   \n",
        "        pool_strides_r2 = pool_strides_r2,                                   \n",
        "        maxpool_q = maxpool_q,                                               \n",
        "        conv_strides_q = conv_strides_q,                                     \n",
        "        pool_strides_q = pool_strides_q,                                     \n",
        "        ramp_start = 1e4,                                                       # starting iteration of KL divergence ramp (if using)\n",
        "        ramp_end = 1e5,                                                         # ending iteration of KL divergence ramp (if using)\n",
        "        save_interval=save_interval,                                            \n",
        "        plot_interval=save_interval,                                            \n",
        "        z_dimension=z_dimension,                                              \n",
        "        n_weights_r1 = n_weights_r1,                                         \n",
        "        n_weights_r2 = n_weights_r2,                                         \n",
        "        n_weights_q = n_weights_q,                                           \n",
        "        duration = 1.0,                                                         # length of training/validation/test sample time series in seconds (haven't tried using at any other value than 1s)\n",
        "        r = r,                                                                  \n",
        "        rand_pars=rand_pars,                                                    \n",
        "        corner_parnames = ['m_{1}\\,(\\mathrm{M}_{\\odot})','m_{2}\\,(\\mathrm{M}_{\\odot})','d_{\\mathrm{L}}\\,(\\mathrm{Mpc})','t_{0}\\,(\\mathrm{seconds})',r'{\\alpha}\\,(\\mathrm{rad})','{\\delta}\\,(\\mathrm{rad})'], # latex source parameter labels for plotting\n",
        "        cornercorner_parnames = ['$m_{1}\\,(\\mathrm{M}_{\\odot})$','$m_{2}\\,(\\mathrm{M}_{\\odot})$','$d_{\\mathrm{L}}\\,(\\mathrm{Mpc})$','$t_{0}\\,(\\mathrm{seconds})$',r'${\\alpha}\\,(\\mathrm{rad})$','${\\delta}\\,(\\mathrm{rad})$'], # latex source parameter labels for plotting\n",
        "        ref_geocent_time=ref_geocent_time,                                      \n",
        "        training_data_seed=43,                                                  # tensorflow training random seed number\n",
        "        testing_data_seed=44,                                                   # tensorflow testing random seed number\n",
        "        wrap_pars=[],#['phase','psi','ra'],                                         # Parameters to apply Von Mises wrapping on (not advised to change) \n",
        "        inf_pars=inf_pars,                                                      \n",
        "        train_set_dir=train_set_dir,\n",
        "        test_set_dir=test_set_dir,\n",
        "        pe_dir=pe_dir,\n",
        "        KL_cycles = 1,                                                          # number of cycles to repeat for the KL approximation\n",
        "        samplers=samplers,                                                      \n",
        "    )\n",
        "    return params\n",
        "\n",
        "\n",
        "# Save training/test parameters of run\n",
        "params=get_params()\n",
        "f = open(\"params_%s.txt\" % params['run_label'],\"w\")\n",
        "f.write( str(params) )\n",
        "f.close()\n",
        "f = open(\"params_%s_bounds.txt\" % params['run_label'],\"w\")\n",
        "f.write( str(bounds) )\n",
        "f.close()\n",
        "f = open(\"params_%s_fixed_vals.txt\" % params['run_label'],\"w\")\n",
        "f.write( str(fixed_vals) )\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbVDzVuBciLz",
        "colab_type": "text"
      },
      "source": [
        "### Generate Requested number of testing samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1oK3PUnR72q",
        "colab_type": "text"
      },
      "source": [
        "Feel free to use the below command in your own time to generate more testing data. \n",
        "\n",
        "In the paper, we used a total of ~256 test samples. It is recommmened that if you are going to run this many test samples, that you split the test runs over condor.\n",
        "\n",
        "In the notebook, I have provided 4 test cases using the dynesty sampler with 500 live points\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Note: DO NOT run this if you wish to use the pre-generated test data provided in the Github repo. If you'd like to make your own test sets, but also keep the pre-generated sets provided, make sure to change the `bilby_results_label` variable to something new.**\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/gw3IWyGkC0rsazTi/giphy.gif\" width=\"400\" height=\"400\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDn2H-klrZE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python VICI_code_usage_example.py --help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL7wQwyMM3Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python VICI_code_usage_example.py --gen_test True --params_file params_ozgrav-demo_3det_6par_256Hz_run1.txt --params_file_bounds params_ozgrav-demo_3det_6par_256Hz_run1_bounds.txt --params_file_fixed_vals params_ozgrav-demo_3det_6par_256Hz_run1_fixed_vals.txt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhhXcM5NW92Q",
        "colab_type": "text"
      },
      "source": [
        "## Generate Traning Samples\n",
        "\n",
        "Demo default parameters are set to generate ~10,000 training samples, though for best results greater than 1 million samples is recommened (ideally 10 million).\n",
        "\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/sULKEgDMX8LcI/giphy.gif\" width=\"600\" height=\"200\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3euU5D6zXCGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python VICI_code_usage_example.py --gen_train True --params_file params_ozgrav-demo_3det_6par_256Hz_run1.txt --params_file_bounds params_ozgrav-demo_3det_6par_256Hz_run1_bounds.txt --params_file_fixed_vals params_ozgrav-demo_3det_6par_256Hz_run1_fixed_vals.txt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XmOPmHJ3PT1u"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "Training utilizes the K80 GPU available to use on the google colab tutorial for free. In the paper we use the NVIDIA DGX1 machine GPUs (just one) at the detector sites. Large convolutional models can take up to 8 - 16 Gb of GPU memory, so it is recommended to use as high end of a GPU as is available to you. \n",
        "\n",
        "If you're limited by the quality of GPU, try removing all convolutional layers by setting `n_filters_r1`, `n_filters_r2` and `n_filters_q` to `None`.\n",
        "\n",
        "Corner plots are generated every 50,000 iterations in the results directory.\n",
        "\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/gZqDdFC62X6KY/giphy.gif\" width=\"600\" height=\"400\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TN5F_GVfPkWQ"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgMNjoMhPrHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78a71296-737e-4a3e-8c28-8aa4deb74ef0"
      },
      "source": [
        "!python VICI_code_usage_example.py --train True --params_file params_ozgrav-demo_3det_6par_256Hz_run1.txt --params_file_bounds params_ozgrav-demo_3det_6par_256Hz_run1_bounds.txt --params_file_fixed_vals params_ozgrav-demo_3det_6par_256Hz_run1_fixed_vals.txt "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-16 20:51:52.764767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "20:51 bilby INFO    : Running bilby version: 0.5.5:\n",
            "/usr/local/lib/python3.6/dist-packages/bilby/core/utils.py:903: MatplotlibDeprecationWarning: The 'warn' parameter of use() is deprecated since Matplotlib 3.1 and will be removed in 3.3.  If any parameter follows 'warn', they should be pass as keyword, not positionally.\n",
            "  matplotlib.use(backend, warn=False)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "2020-06-16 20:51:56.418601: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
            "2020-06-16 20:51:56.418832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d88f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-16 20:51:56.418869: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-16 20:51:56.424152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-16 20:51:56.570397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:51:56.571093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d88d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-16 20:51:56.571140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-06-16 20:51:56.571353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:51:56.571906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-06-16 20:51:56.571967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-16 20:51:56.572045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-16 20:51:56.572082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-16 20:51:56.572118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-16 20:51:56.572182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-16 20:51:56.573508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-16 20:51:56.573588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-16 20:51:56.573689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:51:56.574322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:51:56.574838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-06-16 20:51:56.574886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-16 20:51:57.223568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-16 20:51:57.223628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-06-16 20:51:57.223642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-06-16 20:51:57.223931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:51:57.224601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:51:57.225244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13947 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "data_40000-100000.h5py\n",
            "data_57000-100000.h5py\n",
            "data_80000-100000.h5py\n",
            "data_50000-100000.h5py\n",
            "data_32000-100000.h5py\n",
            "data_61000-100000.h5py\n",
            "data_2000-100000.h5py\n",
            "data_45000-100000.h5py\n",
            "data_30000-100000.h5py\n",
            "data_82000-100000.h5py\n",
            "data_48000-100000.h5py\n",
            "data_69000-100000.h5py\n",
            "data_36000-100000.h5py\n",
            "data_89000-100000.h5py\n",
            "data_52000-100000.h5py\n",
            "data_100000-100000.h5py\n",
            "data_38000-100000.h5py\n",
            "data_76000-100000.h5py\n",
            "data_75000-100000.h5py\n",
            "data_47000-100000.h5py\n",
            "data_94000-100000.h5py\n",
            "data_60000-100000.h5py\n",
            "data_71000-100000.h5py\n",
            "data_55000-100000.h5py\n",
            "data_7000-100000.h5py\n",
            "data_11000-100000.h5py\n",
            "data_99000-100000.h5py\n",
            "data_87000-100000.h5py\n",
            "data_6000-100000.h5py\n",
            "data_27000-100000.h5py\n",
            "data_35000-100000.h5py\n",
            "data_54000-100000.h5py\n",
            "data_29000-100000.h5py\n",
            "data_34000-100000.h5py\n",
            "data_22000-100000.h5py\n",
            "data_8000-100000.h5py\n",
            "data_64000-100000.h5py\n",
            "data_1000-100000.h5py\n",
            "data_33000-100000.h5py\n",
            "data_14000-100000.h5py\n",
            "data_31000-100000.h5py\n",
            "data_72000-100000.h5py\n",
            "data_83000-100000.h5py\n",
            "data_81000-100000.h5py\n",
            "data_77000-100000.h5py\n",
            "data_10000-100000.h5py\n",
            "data_73000-100000.h5py\n",
            "data_67000-100000.h5py\n",
            "data_13000-100000.h5py\n",
            "data_42000-100000.h5py\n",
            "data_93000-100000.h5py\n",
            "data_37000-100000.h5py\n",
            "data_20000-100000.h5py\n",
            "data_85000-100000.h5py\n",
            "data_70000-100000.h5py\n",
            "data_88000-100000.h5py\n",
            "data_43000-100000.h5py\n",
            "data_21000-100000.h5py\n",
            "data_15000-100000.h5py\n",
            "data_74000-100000.h5py\n",
            "data_68000-100000.h5py\n",
            "data_66000-100000.h5py\n",
            "data_92000-100000.h5py\n",
            "data_59000-100000.h5py\n",
            "data_63000-100000.h5py\n",
            "data_49000-100000.h5py\n",
            "data_19000-100000.h5py\n",
            "data_23000-100000.h5py\n",
            "data_3000-100000.h5py\n",
            "data_96000-100000.h5py\n",
            "data_44000-100000.h5py\n",
            "data_56000-100000.h5py\n",
            "data_98000-100000.h5py\n",
            "data_17000-100000.h5py\n",
            "data_65000-100000.h5py\n",
            "data_86000-100000.h5py\n",
            "data_84000-100000.h5py\n",
            "data_91000-100000.h5py\n",
            "data_9000-100000.h5py\n",
            "data_90000-100000.h5py\n",
            "data_46000-100000.h5py\n",
            "data_24000-100000.h5py\n",
            "data_39000-100000.h5py\n",
            "data_25000-100000.h5py\n",
            "data_53000-100000.h5py\n",
            "data_41000-100000.h5py\n",
            "data_12000-100000.h5py\n",
            "data_62000-100000.h5py\n",
            "data_97000-100000.h5py\n",
            "data_78000-100000.h5py\n",
            "data_18000-100000.h5py\n",
            "data_51000-100000.h5py\n",
            "data_58000-100000.h5py\n",
            "data_4000-100000.h5py\n",
            "data_5000-100000.h5py\n",
            "data_26000-100000.h5py\n",
            "data_79000-100000.h5py\n",
            "data_28000-100000.h5py\n",
            "data_95000-100000.h5py\n",
            "data_16000-100000.h5py\n",
            "luminosity_distance\n",
            "geocent_time\n",
            "ra\n",
            "dec\n",
            "data_0.h5py\n",
            "data_1.h5py\n",
            "data_2.h5py\n",
            "data_3.h5py\n",
            "luminosity_distance\n",
            "geocent_time\n",
            "ra\n",
            "dec\n",
            "test_sets/ozgrav-demo/four_parameter_case/test_dynesty1/ozgrav-demo_0.h5py\n",
            "test_sets/ozgrav-demo/four_parameter_case/test_dynesty1/ozgrav-demo_1.h5py\n",
            "test_sets/ozgrav-demo/four_parameter_case/test_dynesty1/ozgrav-demo_2.h5py\n",
            "test_sets/ozgrav-demo/four_parameter_case/test_dynesty1/ozgrav-demo_3.h5py\n",
            "2020-06-16 20:52:09.970476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.971206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-06-16 20:52:09.971271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-16 20:52:09.971305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-16 20:52:09.971328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-16 20:52:09.971347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-16 20:52:09.971365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-16 20:52:09.971438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-16 20:52:09.971458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-16 20:52:09.971566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.972183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.972743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-06-16 20:52:09.973483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.974035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-06-16 20:52:09.974068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-16 20:52:09.974093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-16 20:52:09.974113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-16 20:52:09.974133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-16 20:52:09.974148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-16 20:52:09.974183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-16 20:52:09.974201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-16 20:52:09.974279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.974891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.975389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-06-16 20:52:09.975447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-16 20:52:09.975477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-06-16 20:52:09.975487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-06-16 20:52:09.975631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.976263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-16 20:52:09.976890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13947 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/OzGrav_demo/Neural_Networks/VICI_encoder.py:59: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n",
            "Training Inference Model...\n",
            "2020-06-16 20:52:14.097214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-16 20:52:14.391670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "/usr/local/lib/python3.6/dist-packages/gwpy/plot/axes.py:130: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
            "  super(Axes, self).draw(*args, **kwargs)\n",
            "--------------------------------------------------------------\n",
            "Iteration: 500\n",
            "Training -ELBO: -6.574319\n",
            "Validation -ELBO: -5.306048\n",
            "Training KL Divergence: 175.04794\n",
            "Validation KL Divergence: 178.02441\n",
            "Training Total cost: 168.47362\n",
            "Validation Total cost: 172.71837\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 1000\n",
            "Training -ELBO: -6.528271\n",
            "Validation -ELBO: -5.452222\n",
            "Training KL Divergence: 195.7081\n",
            "Validation KL Divergence: 173.26166\n",
            "Training Total cost: 189.17982\n",
            "Validation Total cost: 167.80943\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 1500\n",
            "Training -ELBO: -9.181374\n",
            "Validation -ELBO: -9.316105\n",
            "Training KL Divergence: 281.31427\n",
            "Validation KL Divergence: 262.21445\n",
            "Training Total cost: 272.1329\n",
            "Validation Total cost: 252.89835\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 2000\n",
            "Training -ELBO: 3.6663194\n",
            "Validation -ELBO: 0.8497994\n",
            "Training KL Divergence: 336.04266\n",
            "Validation KL Divergence: 313.28452\n",
            "Training Total cost: 339.70898\n",
            "Validation Total cost: 314.1343\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 2500\n",
            "Training -ELBO: -9.741327\n",
            "Validation -ELBO: -10.15781\n",
            "Training KL Divergence: 301.6346\n",
            "Validation KL Divergence: 282.2105\n",
            "Training Total cost: 291.89328\n",
            "Validation Total cost: 272.0527\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 3000\n",
            "Training -ELBO: -10.705406\n",
            "Validation -ELBO: -11.308442\n",
            "Training KL Divergence: 284.4176\n",
            "Validation KL Divergence: 264.54462\n",
            "Training Total cost: 273.7122\n",
            "Validation Total cost: 253.23618\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 3500\n",
            "Training -ELBO: 1.7785848\n",
            "Validation -ELBO: -6.7317443\n",
            "Training KL Divergence: 288.91235\n",
            "Validation KL Divergence: 262.10526\n",
            "Training Total cost: 290.69095\n",
            "Validation Total cost: 255.3735\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 4000\n",
            "Training -ELBO: -11.544292\n",
            "Validation -ELBO: -11.154427\n",
            "Training KL Divergence: 324.72943\n",
            "Validation KL Divergence: 291.79114\n",
            "Training Total cost: 313.18515\n",
            "Validation Total cost: 280.63672\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 4500\n",
            "Training -ELBO: -14.027308\n",
            "Validation -ELBO: -14.150941\n",
            "Training KL Divergence: 352.4147\n",
            "Validation KL Divergence: 329.26013\n",
            "Training Total cost: 338.3874\n",
            "Validation Total cost: 315.1092\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 5000\n",
            "Training -ELBO: -13.155389\n",
            "Validation -ELBO: -13.454191\n",
            "Training KL Divergence: 380.21844\n",
            "Validation KL Divergence: 343.7409\n",
            "Training Total cost: 367.06305\n",
            "Validation Total cost: 330.2867\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 5500\n",
            "Training -ELBO: -14.762042\n",
            "Validation -ELBO: -14.996166\n",
            "Training KL Divergence: 392.45996\n",
            "Validation KL Divergence: 358.95538\n",
            "Training Total cost: 377.6979\n",
            "Validation Total cost: 343.95923\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 6000\n",
            "Training -ELBO: -14.192114\n",
            "Validation -ELBO: -14.592513\n",
            "Training KL Divergence: 378.27698\n",
            "Validation KL Divergence: 347.04248\n",
            "Training Total cost: 364.08487\n",
            "Validation Total cost: 332.44998\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 6500\n",
            "Training -ELBO: -9.100174\n",
            "Validation -ELBO: -9.53352\n",
            "Training KL Divergence: 403.0442\n",
            "Validation KL Divergence: 363.27097\n",
            "Training Total cost: 393.94403\n",
            "Validation Total cost: 353.73746\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 7000\n",
            "Training -ELBO: -14.425821\n",
            "Validation -ELBO: -14.495509\n",
            "Training KL Divergence: 412.15515\n",
            "Validation KL Divergence: 369.3216\n",
            "Training Total cost: 397.72934\n",
            "Validation Total cost: 354.82608\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 7500\n",
            "Training -ELBO: -8.007004\n",
            "Validation -ELBO: -9.590897\n",
            "Training KL Divergence: 428.17163\n",
            "Validation KL Divergence: 388.42688\n",
            "Training Total cost: 420.1646\n",
            "Validation Total cost: 378.836\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 8000\n",
            "Training -ELBO: -15.094212\n",
            "Validation -ELBO: -15.393225\n",
            "Training KL Divergence: 443.87595\n",
            "Validation KL Divergence: 387.3009\n",
            "Training Total cost: 428.78174\n",
            "Validation Total cost: 371.90768\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 8500\n",
            "Training -ELBO: -14.90696\n",
            "Validation -ELBO: -15.597815\n",
            "Training KL Divergence: 406.55026\n",
            "Validation KL Divergence: 353.75058\n",
            "Training Total cost: 391.6433\n",
            "Validation Total cost: 338.15277\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 9000\n",
            "Training -ELBO: -13.13324\n",
            "Validation -ELBO: -12.25408\n",
            "Training KL Divergence: 366.95056\n",
            "Validation KL Divergence: 324.45242\n",
            "Training Total cost: 353.81732\n",
            "Validation Total cost: 312.19833\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 9500\n",
            "Training -ELBO: -15.268835\n",
            "Validation -ELBO: -15.852186\n",
            "Training KL Divergence: 449.18832\n",
            "Validation KL Divergence: 408.58856\n",
            "Training Total cost: 433.9195\n",
            "Validation Total cost: 392.7364\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 10000\n",
            "Training -ELBO: -14.974421\n",
            "Validation -ELBO: -15.321458\n",
            "Training KL Divergence: 423.20312\n",
            "Validation KL Divergence: 383.8926\n",
            "Training Total cost: 408.2287\n",
            "Validation Total cost: 368.57114\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 10500\n",
            "Training -ELBO: -13.64754\n",
            "Validation -ELBO: -13.105168\n",
            "Training KL Divergence: 110.533035\n",
            "Validation KL Divergence: 95.927124\n",
            "Training Total cost: 96.8855\n",
            "Validation Total cost: 82.82195\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 11000\n",
            "Training -ELBO: -12.84498\n",
            "Validation -ELBO: -13.105739\n",
            "Training KL Divergence: 67.069756\n",
            "Validation KL Divergence: 65.713425\n",
            "Training Total cost: 54.224777\n",
            "Validation Total cost: 52.607685\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 11500\n",
            "Training -ELBO: -13.182223\n",
            "Validation -ELBO: -12.967328\n",
            "Training KL Divergence: 49.4422\n",
            "Validation KL Divergence: 54.648445\n",
            "Training Total cost: 36.259975\n",
            "Validation Total cost: 41.681118\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 12000\n",
            "Training -ELBO: -12.779772\n",
            "Validation -ELBO: -12.242018\n",
            "Training KL Divergence: 37.862946\n",
            "Validation KL Divergence: 38.679848\n",
            "Training Total cost: 25.083174\n",
            "Validation Total cost: 26.43783\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 12500\n",
            "Training -ELBO: -12.327696\n",
            "Validation -ELBO: -12.569212\n",
            "Training KL Divergence: 28.892612\n",
            "Validation KL Divergence: 31.814997\n",
            "Training Total cost: 16.564917\n",
            "Validation Total cost: 19.245785\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 13000\n",
            "Training -ELBO: -12.40797\n",
            "Validation -ELBO: -12.775991\n",
            "Training KL Divergence: 27.007418\n",
            "Validation KL Divergence: 27.532667\n",
            "Training Total cost: 14.599447\n",
            "Validation Total cost: 14.756676\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 13500\n",
            "Training -ELBO: -12.551289\n",
            "Validation -ELBO: -12.303318\n",
            "Training KL Divergence: 23.721165\n",
            "Validation KL Divergence: 24.443943\n",
            "Training Total cost: 11.169876\n",
            "Validation Total cost: 12.140625\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 14000\n",
            "Training -ELBO: -12.682235\n",
            "Validation -ELBO: -13.455637\n",
            "Training KL Divergence: 20.550896\n",
            "Validation KL Divergence: 20.572401\n",
            "Training Total cost: 7.868661\n",
            "Validation Total cost: 7.116764\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 14500\n",
            "Training -ELBO: -13.498699\n",
            "Validation -ELBO: -12.080312\n",
            "Training KL Divergence: 18.726044\n",
            "Validation KL Divergence: 18.258781\n",
            "Training Total cost: 5.2273445\n",
            "Validation Total cost: 6.1784697\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 15000\n",
            "Training -ELBO: -13.712797\n",
            "Validation -ELBO: -12.096975\n",
            "Training KL Divergence: 17.067265\n",
            "Validation KL Divergence: 15.161701\n",
            "Training Total cost: 3.3544674\n",
            "Validation Total cost: 3.0647259\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 15500\n",
            "Training -ELBO: -13.579115\n",
            "Validation -ELBO: -12.841906\n",
            "Training KL Divergence: 15.864045\n",
            "Validation KL Divergence: 14.564599\n",
            "Training Total cost: 2.2849302\n",
            "Validation Total cost: 1.7226934\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 16000\n",
            "Training -ELBO: -13.437641\n",
            "Validation -ELBO: -13.32255\n",
            "Training KL Divergence: 15.797756\n",
            "Validation KL Divergence: 17.084217\n",
            "Training Total cost: 2.360115\n",
            "Validation Total cost: 3.7616673\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 16500\n",
            "Training -ELBO: -13.689709\n",
            "Validation -ELBO: -13.933493\n",
            "Training KL Divergence: 16.009434\n",
            "Validation KL Divergence: 16.106703\n",
            "Training Total cost: 2.319725\n",
            "Validation Total cost: 2.1732101\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 17000\n",
            "Training -ELBO: -13.85079\n",
            "Validation -ELBO: -13.31567\n",
            "Training KL Divergence: 15.036033\n",
            "Validation KL Divergence: 14.649147\n",
            "Training Total cost: 1.1852427\n",
            "Validation Total cost: 1.333477\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 17500\n",
            "Training -ELBO: -14.104166\n",
            "Validation -ELBO: -13.924367\n",
            "Training KL Divergence: 13.852631\n",
            "Validation KL Divergence: 14.966269\n",
            "Training Total cost: -0.25153542\n",
            "Validation Total cost: 1.0419016\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Iteration: 18000\n",
            "Training -ELBO: -14.017017\n",
            "Validation -ELBO: -14.747887\n",
            "Training KL Divergence: 15.089004\n",
            "Validation KL Divergence: 15.075749\n",
            "Training Total cost: 1.0719862\n",
            "Validation Total cost: 0.32786274\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"VICI_code_usage_example.py\", line 655, in <module>\n",
            "    XS_all,snrs_test) \n",
            "  File \"/content/OzGrav_demo/Models/VICI_inverse_model.py\", line 351, in train\n",
            "    session.run(minimize, feed_dict={bs_ph:bs, x_ph:next_x_data, y_ph:next_y_data, idx:i})\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 958, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1181, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwOb6ifX8KGa",
        "colab_type": "text"
      },
      "source": [
        "### Show progress of training run in plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls5scCOP8e-k",
        "colab_type": "text"
      },
      "source": [
        "Cost function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfjBaFRz8RQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='%s/latest_%s/cost_zoom_%s.png' % (params['plot_dir'],params['run_label'],params['run_label'])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dykgX5ks8tGd",
        "colab_type": "text"
      },
      "source": [
        "Current Training results:\n",
        "\n",
        "Red is VItamin, Blue is Dynesty. Predicted source parameters are shown in normalized form (i.e. zero to one)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0utqKEu8wbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(params['r']**2):\n",
        "    display(Image(filename='%s/latest_%s/corner_plot_%s_%d.png' % (params['plot_dir'],params['run_label'],params['run_label'],i))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F9AgkZ3-pIP",
        "colab_type": "text"
      },
      "source": [
        "To resume training, just set `resume_training` option in command line to True.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yYL4YrXAUYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python VICI_code_usage_example.py --resume_training True --params_file params_ozgrav-demo_3det_6par_256Hz_run1.txt --params_file_bounds params_ozgrav-demo_3det_6par_256Hz_run1_bounds.txt --params_file_fixed_vals params_ozgrav-demo_3det_6par_256Hz_run1_fixed_vals.txt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeE98hRnXadJ",
        "colab_type": "text"
      },
      "source": [
        "## Compare Bilby vs. VItamin\n",
        "\n",
        "This will produce three sets of plots: Corner plots comparing VItamin samples with all other requested Bayesian samples, KL divergence plots showing the KL divergence between VItamin and Bayesian samplers (ideally we should see that all colored distributions are consistent with non-colored) and P-P plots which show how generally consistent with the truth each sampler is (ideally all samplers line up along the diagonal). \n",
        "\n",
        "Plots are stored in the results folder.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Note: Due to time constraints, we will be loading in a pre-trained network. (~5 hrs training)**\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/cIWwi5umxQRNOwrJm4/giphy.gif\" width=\"400\" height=\"400\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jmw5PD1xiHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pre-trained model\n",
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='19s59WfRJnF4xkFpYv_vLsqxNAmyaXKvi',\n",
        "                                    dest_path='./pretrained_model/pretrained_model.ckpt.data-00000-of-00001'\n",
        "                                    )\n",
        "gdd.download_file_from_google_drive(file_id='1UU8kK9wrl_EwEEewDVLaD51Veovz6rE9',\n",
        "                                    dest_path='./pretrained_model/pretrained_model.ckpt.index'\n",
        "                                    )\n",
        "gdd.download_file_from_google_drive(file_id='1hAOo4w9fu9kne-tl4g7vVeW4n4zpcV5m',\n",
        "                                    dest_path='./pretrained_model/pretrained_model.ckpt.meta'\n",
        "                                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sGBzCe9AyB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python VICI_code_usage_example.py --test True --pretrained_loc pretrained_model/pretrained_model.ckpt --params_file params_ozgrav-demo_3det_6par_256Hz_run1.txt --params_file_bounds params_ozgrav-demo_3det_6par_256Hz_run1_bounds.txt --params_file_fixed_vals params_ozgrav-demo_3det_6par_256Hz_run1_fixed_vals.txt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwO6Lepzqqgb",
        "colab_type": "text"
      },
      "source": [
        "### Plot final results on pre-trained network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnIceO0JDDP2",
        "colab_type": "text"
      },
      "source": [
        "Corner plots:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUCJfzyeDCrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(params['r']**2):\n",
        "    display(Image(filename='%s/latest_%s/corner_plot_%s_%d.png' % (params['plot_dir'],params['run_label'],params['run_label'],i))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAbFbWmhDGtW",
        "colab_type": "text"
      },
      "source": [
        "KL plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqBJ2m7cDImh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='%s/latest_%s/hist-kl.png' % (params['plot_dir'],params['run_label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF82555FDJGT",
        "colab_type": "text"
      },
      "source": [
        "P-P plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzO7MHoyDK4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='%s/latest_%s/latest_pp_plot.png' % (params['plot_dir'],params['run_label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuQGioQQqHyM",
        "colab_type": "text"
      },
      "source": [
        "### Optimal results\n",
        "\n",
        "Eventually, you want to get results that look like these:\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/NEvPzZ8bd1V4Y/giphy.gif\" width=\"400\" height=\"400\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEVzogpmrVPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='corner_testcase0.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXjuAt0YM7kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='inv_losses_log.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbLATL2TM9c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='latest_pp_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXo27hs3NG2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='hist-kl.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZdzHYaSVPvb",
        "colab_type": "text"
      },
      "source": [
        "# Noninteractive: Background\n",
        "\n",
        "In the Background section, I will provide some description on the inner workings of the VItamin code. Specifically, I will describe the three neural networks which make up the code (`q`,`r1`,`r2`), as well as the TensorFlow graph which ties all three networks together.\n",
        "\n",
        "\n",
        "**Note: All code cells below are NOT meant to be executable. Just educational.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvTJ5Js5ouz0",
        "colab_type": "text"
      },
      "source": [
        "## Network Training Portion of VItamin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0mWXk0Lzduz",
        "colab_type": "text"
      },
      "source": [
        "Since the code runs on TensorFlow 1.0 we need to define a TensorFlow session where the computational graph will execute. This is not necessary to do in TensorFlow 2.0. \n",
        "\n",
        "We also need to define place holders for future inputs to be used when we eventually go to train the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMOPeFqezZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = tf.Graph()                                                              # Define computational graph\n",
        "session = tf.Session(graph=graph)                                               # Define TensorFlow session which will run computational graph\n",
        "with graph.as_default():                                                        # Start of computational graph\n",
        "\n",
        "    # PLACE HOLDERS\n",
        "    bs_ph = tf.placeholder(dtype=tf.int64, name=\"bs_ph\")                        # batch size placeholder\n",
        "    x_ph = tf.placeholder(dtype=tf.float32, shape=[None, xsh[1]], name=\"x_ph\")  # infered source parameters placeholder\n",
        "    if n_conv_r1 != None:\n",
        "        if params['by_channel'] == True:\n",
        "            y_ph = tf.placeholder(dtype=tf.float32, shape=[None,ysh,len(fixed_vals['det'])], name=\"y_ph\") # GW time series placeholder if channels last\n",
        "        else:\n",
        "            y_ph = tf.placeholder(dtype=tf.float32, shape=[None,len(fixed_vals['det']),ysh], name=\"y_ph\") # GW time series placeholder if channels first\n",
        "    else:\n",
        "        y_ph = tf.placeholder(dtype=tf.float32, shape=[None,ysh], name=\"y_ph\")  # GW time series place holder if no convolutional layers\n",
        "    idx = tf.placeholder(tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsbJ-xY3z4G0",
        "colab_type": "text"
      },
      "source": [
        "Define and import from the `Neural_Networks` folder the three TensorFlow networks we will be training. (i.e. `r1_zy`, `r2_xzy` and `q_zxy`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMSaz_kw0Fqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # LOAD VItamin NEURAL NETWORKS\n",
        "    r2_xzy = VICI_decoder.VariationalAutoencoder('VICI_decoder', wrap_mask, nowrap_mask, \n",
        "                                                  n_input1=z_dimension, n_input2=ysh_conv_r2, n_output=xsh[1], \n",
        "                                                  n_weights=n_weights_r2, n_hlayers=n_hlayers_r2, \n",
        "                                                  drate=drate, n_filters=n_filters_r2, filter_size=filter_size_r2,\n",
        "                                                  maxpool=maxpool_r2, n_conv=n_conv_r2, conv_strides=conv_strides_r2, pool_strides=pool_strides_r2, num_det=num_det, batch_norm=batch_norm, by_channel=params['by_channel'], weight_init=params['weight_init'])\n",
        "    r1_zy = VICI_encoder.VariationalAutoencoder('VICI_encoder', n_input=ysh_conv_r1, n_output=z_dimension, \n",
        "                                                  n_weights=n_weights_r1, n_modes=n_modes, \n",
        "                                                  n_hlayers=n_hlayers_r1, drate=drate, n_filters=n_filters_r1, \n",
        "                                                  filter_size=filter_size_r1,maxpool=maxpool_r1, n_conv=n_conv_r1, conv_strides=conv_strides_r1, pool_strides=pool_strides_r1, num_det=num_det, batch_norm=batch_norm, by_channel=params['by_channel'], weight_init=params['weight_init'])\n",
        "    q_zxy = VICI_VAE_encoder.VariationalAutoencoder('VICI_VAE_encoder', n_input1=xsh[1], n_input2=ysh_conv_q, \n",
        "                                                    n_output=z_dimension, n_weights=n_weights_q, \n",
        "                                                    n_hlayers=n_hlayers_q, drate=drate, n_filters=n_filters_q, \n",
        "                                                    filter_size=filter_size_q,maxpool=maxpool_q, n_conv=n_conv_q, conv_strides=conv_strides_q, pool_strides=pool_strides_q, num_det=num_det, batch_norm=batch_norm, by_channel=params['by_channel'], weight_init=params['weight_init']) # used to sample from q(z|x,y)?\n",
        "    tf.set_random_seed(np.random.randint(0,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hXt7oht8foX",
        "colab_type": "text"
      },
      "source": [
        "Define a ramp for use later which is linear in log space on the Kubler-Leibeck divergence loss term."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43mki4md854f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    ramp = (tf.log(tf.dtypes.cast(idx,dtype=tf.float32)) - tf.log(ramp_start))/(tf.log(ramp_end)-tf.log(ramp_start))\n",
        "    ramp = tf.minimum(tf.math.maximum(0.0,ramp),1.0)\n",
        "        \n",
        "    if params['ramp'] == False:\n",
        "        ramp = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21nGKlh688GO",
        "colab_type": "text"
      },
      "source": [
        "Get the encoder network r1(z|y) latent predicted mean, log variances and mode weights of latent space Gaussian distributions. (i.e. r1(z|y))\n",
        "\n",
        "*   `r1_loc.shape` = `(batch_size, modes, latent_space_dimensions)`\n",
        "*   `r1_scale.shape` = `(batch_size, modes, latent_space_dimensions)`\n",
        "*   `r1_weight.shape` = `(batch_size, modes)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVMOs-Dt-oVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # reduce the y data size. TODO: This is redundant, remove.\n",
        "    y_conv = y_ph\n",
        "\n",
        "    # GET r1(z|y)\n",
        "    # run inverse autoencoder to generate mean and logvar of z given y data - these are the parameters for r1(z|y)\n",
        "    r1_loc, r1_scale, r1_weight = r1_zy._calc_z_mean_and_sigma(y_conv)\n",
        "    r1_scale = tf.sqrt(SMALL_CONSTANT + tf.exp(r1_scale))\n",
        "\n",
        "    # apply KL ramp to r1_weight\n",
        "    r1_weight = ramp*tf.squeeze(r1_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNnEI-ZkAwiA",
        "colab_type": "text"
      },
      "source": [
        "**Define and draw from r1(z|y) mixture model**\n",
        "\n",
        "We define a Gaussian mixture model, given predicted means (`r1_loc`), log variances (`r1_scale`) and mode weights (`r1_weight`) from the r1 network. This encourages the generation of multi-modal posteriors.\n",
        "\n",
        "`mixture_distribution` argument tell us the probability that we will draw from a particular mode. `components_distribution` are the components from which we will draw samples.\n",
        "\n",
        "We can then sample from this distribution in order to get out a single sample from each of the r1 latent space dimensions for every training case in batch (r1_zy_samp).\n",
        "\n",
        "\n",
        "Variable shapes:\n",
        "*   `r1_zy_samp.shape` = `(batch_size, latent_space_dimensions)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oKmSdWrAwMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # define the r1(z|y) mixture model\n",
        "    bimix_gauss = tfd.MixtureSameFamily(\n",
        "                      mixture_distribution=tfd.Categorical(logits=ramp*r1_weight),\n",
        "                      components_distribution=tfd.MultivariateNormalDiag(\n",
        "                      loc=r1_loc,\n",
        "                      scale_diag=r1_scale))\n",
        "    # DRAW FROM r1(z|y) - given the Gaussian parameters generate z samples\n",
        "    r1_zy_samp = bimix_gauss.sample()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfoUKrGgE7ak",
        "colab_type": "text"
      },
      "source": [
        "**Get output from q network**\n",
        "\n",
        "Calculate the predicted means and log variances of the q network. Given those means and log variances, retrieve a single sample from each latent space dimension in the form of (`q_zxy_samp`).\n",
        "\n",
        "\n",
        "Variable shapes:\n",
        "*   `q_zxy_mean.shape` = `(batch_size, latent_space_dimensions)`\n",
        "*   `q_zxy_log_sig_sq` = `(batch_size, latent_space_dimensions)`\n",
        "*   `q_zxy_samp` = `(batch_size, latent_space_dimensions)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO89n21-E6HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # GET q(z|x,y)\n",
        "    q_zxy_mean, q_zxy_log_sig_sq = q_zxy._calc_z_mean_and_sigma(x_ph,y_conv)\n",
        "\n",
        "    # DRAW FROM q(z|x,y)\n",
        "    q_zxy_samp = q_zxy._sample_from_gaussian_dist(bs_ph, z_dimension, q_zxy_mean, tf.log(SMALL_CONSTANT + tf.exp(q_zxy_log_sig_sq)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzU46Sx6GqZh",
        "colab_type": "text"
      },
      "source": [
        "**Get output from r2 network**\n",
        "\n",
        "Retrieve predicted means and standard deviations from r2 network. Identify source parameters to apply Von Mises wrapping to.\n",
        "\n",
        "\n",
        "Variable shapes:\n",
        "*   `r2_xzy_mean_nowrap.shape` = `(batch_size, number_unwrapped_parameters)`\n",
        "*   `r2_xzy_log_sig_sq_nowrap.shape` = `(batch_size, number_unwrapped_parameters)`\n",
        "*   `r2_xzy_mean_wrap.shape` = `(batch_size, number_wrapped_parameters)`\n",
        "*   `r2_xzy_log_sig_sq_wrap.shape` = `(batch_size, number_wrapped_parameters)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-o8UNY-GqBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # GET r2(x|z,y)\n",
        "    reconstruction_xzy = r2_xzy.calc_reconstruction(q_zxy_samp,y_conv)\n",
        "    r2_xzy_mean_nowrap = reconstruction_xzy[0]\n",
        "    r2_xzy_log_sig_sq_nowrap = reconstruction_xzy[1]\n",
        "    if np.sum(wrap_mask)>0:\n",
        "        r2_xzy_mean_wrap = reconstruction_xzy[2]\n",
        "        r2_xzy_log_sig_sq_wrap = reconstruction_xzy[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23_r0eA0HbCb",
        "colab_type": "text"
      },
      "source": [
        "**Calculate cost from reconstruction - Gaussian parts**\n",
        "\n",
        "\n",
        "*   `normalising_factor_x`: Define a small normalization factor (for algebra reasons).\n",
        "*   `square_diff_between_mu_and_x`: Compute the mean difference between predicted means from r2 and source parameter truths (essentially a mean squared error).\n",
        "*    `inside_exp_x`: Divide the mean difference by the standard deviation squared.\n",
        "*    `reconstr_loss_x`: Apply small normalization factor (`normalising_factor_x`) to mean difference (`inside_exp_x`) and sum. \n",
        "\n",
        "All this returns the reconstruction loss, or in other words ... how far off the mean locations of the network predicted source parameter Gaussians are from the source parameter truths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rlr-wO7HZjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # COST FROM RECONSTRUCTION - Gaussian parts\n",
        "    normalising_factor_x = -0.5*tf.log(SMALL_CONSTANT + tf.exp(r2_xzy_log_sig_sq_nowrap)) - 0.5*np.log(2.0*np.pi)   # -0.5*log(sig^2) - 0.5*log(2*pi)\n",
        "    square_diff_between_mu_and_x = tf.square(r2_xzy_mean_nowrap - tf.boolean_mask(x_ph,nowrap_mask,axis=1))         # (mu - x)^2\n",
        "\n",
        "    inside_exp_x = -0.5 * tf.divide(square_diff_between_mu_and_x,SMALL_CONSTANT + tf.exp(r2_xzy_log_sig_sq_nowrap)) # -0.5*(mu - x)^2 / sig^2\n",
        "    reconstr_loss_x = tf.reduce_sum(normalising_factor_x + inside_exp_x,axis=1,keepdims=True)                       # sum_dim(-0.5*log(sig^2) - 0.5*log(2*pi) - 0.5*(mu - x)^2 / sig^2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeYePUPaK19a",
        "colab_type": "text"
      },
      "source": [
        "**Calculate cost from reconstruction - Von Mises and add to Gaussian cost**\n",
        "\n",
        "We use a Von Mises distribution, rather than a Gaussian, on `r2` network predicted source parameters we know to have periodic-like distributions.\n",
        "\n",
        "\n",
        "\n",
        "*   `con`: the concentration of the Von Mises distribtion (similar to standard deviation parameter in Gaussian distribution).\n",
        "*   `von_loc`: the circular mean of the Von Mises distribution (similar the the mean of a Gaussian).\n",
        "\n",
        "We get out a loss for Von Mises parameters by computing the log probability evaluated at the source parameter truths.\n",
        "\n",
        "\n",
        "\n",
        "*   `cost_R`: Add reconstruction loss from Von Mises and Gaussian together.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDpz8NpKKxj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # COST FROM RECONSTRUCTION - Von Mises parts\n",
        "    if np.sum(wrap_mask)>0:                                                     # enter if applying Von Mises wrapping to infered parameters\n",
        "\n",
        "        con = tf.reshape(tf.math.reciprocal(SMALL_CONSTANT + tf.exp(r2_xzy_log_sig_sq_wrap)),[-1,wrap_len])                                             # modelling wrapped scale output as log variance\n",
        "        von_loc = 2.0*np.pi*(tf.reshape(r2_xzy_mean_wrap,[-1,wrap_len])-0.5)                                                                            # get locations\n",
        "\n",
        "        von_mises = tfp.distributions.VonMises(loc=von_loc, concentration=con)                                                                          # define p_vm(2*pi*mu,con=1/sig^2)\n",
        "        reconstr_loss_vm = tf.reduce_sum(von_mises.log_prob(2.0*np.pi*(tf.reshape(tf.boolean_mask(x_ph,wrap_mask,axis=1),[-1,wrap_len]) - 0.5)),axis=1) # 2pi is the von mises input range\n",
        " \n",
        "        r2_xzy_mean = tf.gather(tf.concat([r2_xzy_mean_nowrap,r2_xzy_mean_wrap],axis=1),tf.constant(idx_mask),axis=1)\n",
        "        r2_xzy_scale = tf.gather(tf.concat([r2_xzy_log_sig_sq_nowrap,r2_xzy_log_sig_sq_wrap],axis=1),tf.constant(idx_mask),axis=1) \n",
        " \n",
        "        cost_R = -1.0*tf.reduce_mean(reconstr_loss_x + reconstr_loss_vm)                                                                                # average over batch\n",
        "    else:\n",
        "        cost_R = -1.0*tf.reduce_mean(reconstr_loss_x)    \n",
        "        r2_xzy_mean = r2_xzy_mean_nowrap\n",
        "        r2_xzy_scale = r2_xzy_log_sig_sq_nowrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXssQBJTMh24",
        "colab_type": "text"
      },
      "source": [
        "Compute the level of uncertainty in q. Basically do the same set of operations done on r2 earlier. Compute mean squared difference between predicted means from q and samples of the latent space from q and normalize. Essentially, we don't want the locations of the predicted latent space Gaussian to be all over the place. We want them to settle into a local minimum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rthZxyn6MhrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # compute montecarlo KL - first compute the analytic self entropy of q \n",
        "    normalising_factor_kl = -0.5*tf.log(SMALL_CONSTANT + tf.exp(q_zxy_log_sig_sq)) - 0.5*np.log(2.0*np.pi)   # -0.5*log(sig^2) - 0.5*log(2*pi)\n",
        "    square_diff_between_qz_and_q = tf.square(q_zxy_mean - q_zxy_samp)                                        # (mu - x)^2\n",
        "    inside_exp_q = -0.5 * tf.divide(square_diff_between_qz_and_q,SMALL_CONSTANT + tf.exp(q_zxy_log_sig_sq))  # -0.5*(mu - x)^2 / sig^2\n",
        "    log_q_q = tf.reduce_sum(normalising_factor_kl + inside_exp_q,axis=1,keepdims=True)                       # sum_dim(-0.5*log(sig^2) - 0.5*log(2*pi) - 0.5*(mu - x)^2 / sig^2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPQYTPNrN2rs",
        "colab_type": "text"
      },
      "source": [
        "Calculate the mean KL divergence between the sum of the uncertainty in q over the whole batch and log probability of r1 at q samples over the whole batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y54qTq2VN2IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    log_r1_q = bimix_gauss.log_prob(q_zxy_samp)   # evaluate the log prob of r1 at the q samples\n",
        "    KL = tf.reduce_mean(log_q_q - log_r1_q)      # average over batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKaMDpMsPL_7",
        "colab_type": "text"
      },
      "source": [
        "**Compute total loss of networks**\n",
        "\n",
        "Get total loss of network by adding KL divergence (scaled by a ramp factor) to the reconstruction loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG-2nWZvPL2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # THE VICI COST FUNCTION\n",
        "    COST = cost_R + ramp*KL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g241y8kFPbBZ",
        "colab_type": "text"
      },
      "source": [
        "**Define a gradient optimizer and initialize the session**\n",
        "\n",
        "\n",
        "Colate all variables (weights, biases, etc.) of the network into a list. Define an optimizer to use. Initialize and run the whole session. Define function to save network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBHd896AVRs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # VARIABLES LISTS\n",
        "    var_list_VICI = [var for var in tf.trainable_variables() if var.name.startswith(\"VICI\")]\n",
        "        \n",
        "    # DEFINE OPTIMISER (using ADAM here)\n",
        "    optimizer = tf.train.AdamOptimizer(params['initial_training_rate']) \n",
        "    minimize = optimizer.minimize(COST,var_list = var_list_VICI)\n",
        "        \n",
        "    # INITIALISE AND RUN SESSION\n",
        "    init = tf.global_variables_initializer()\n",
        "    session.run(init)\n",
        "    saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIIMnNVpba64",
        "colab_type": "text"
      },
      "source": [
        "**Train the network graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNyEwDd7beZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Inference Model...')    \n",
        "# START OPTIMISATION OF OELBO\n",
        "indices_generator = batch_manager.SequentialIndexer(params['batch_size'], xsh[0])\n",
        "\n",
        "load_chunk_it = 1\n",
        "# Iterate over requested number of training iterations\n",
        "for i in range(params['num_iterations']):\n",
        "\n",
        "    next_indices = indices_generator.next_indices()\n",
        "\n",
        "    # if load chunks true, load in data by chunks\n",
        "    if params['load_by_chunks'] == True and i == int(params['load_iteration']*load_chunk_it):\n",
        "        x_data, y_data = load_chunk(params['train_set_dir'],params['inf_pars'],params,bounds,fixed_vals)\n",
        "        load_chunk_it += 1\n",
        "\n",
        "    # Make noise realizations and add to training data\n",
        "    next_x_data = x_data[next_indices,:]\n",
        "    if n_conv_r1 != None:\n",
        "        next_y_data = y_data[next_indices,:] + np.random.normal(0,1,size=(params['batch_size'],int(params['ndata']),len(fixed_vals['det'])))\n",
        "    else:\n",
        "        next_y_data = y_data[next_indices,:] + np.random.normal(0,1,size=(params['batch_size'],int(params['ndata']*len(fixed_vals['det']))))\n",
        "    next_y_data /= y_normscale  # required for fast convergence\n",
        "\n",
        "    if params['by_channel'] == False:\n",
        "        next_y_data_new = [] \n",
        "        for sig in next_y_data:\n",
        "            next_y_data_new.append(sig.T)\n",
        "        next_y_data = np.array(next_y_data_new)\n",
        "        del next_y_data_new\n",
        "       \n",
        "    # restore session if wanted\n",
        "    if params['resume_training'] == True and i == 0 :\n",
        "        print(save_dir)\n",
        "        saver.restore(session, save_dir)\n",
        " \n",
        "    # train to minimise the cost function\n",
        "    session.run(minimize, feed_dict={bs_ph:bs, x_ph:next_x_data, y_ph:next_y_data, idx:i})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MWPzKptpv0q",
        "colab_type": "text"
      },
      "source": [
        "## Q network\n",
        "Encoder network which takes as input time series and source parameter truths. Outputs samples from q network latent space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-mhMu_gkOCS",
        "colab_type": "text"
      },
      "source": [
        "### Define initial variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FDpkEKPkNj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder(object):\n",
        "\n",
        "    def __init__(self, name, n_input1=3, n_input2=256, n_output=4, n_weights=2048, n_hlayers=2, drate=0.2, n_filters=8, filter_size=8, maxpool=4, n_conv=2, conv_strides=1, pool_strides=1, num_det=1, batch_norm=False, by_channel=False, weight_init='xavier'):\n",
        "        \n",
        "        self.n_input1 = n_input1                                                # latent space dimension size\n",
        "        self.n_input2 = n_input2                                                # time series size\n",
        "        self.n_output = n_output                                                # number of source parameters to infer\n",
        "        self.n_weights = n_weights                                              # number of fully-connected neurons in each layer\n",
        "        self.n_hlayers = n_hlayers                                              # number of fully-connected layers\n",
        "        self.n_conv = n_conv                                                    # number of convolutional layers\n",
        "        self.drate = drate                                                      # drop out rate in fully-connected layers\n",
        "        self.n_filters = n_filters                                              # number of filters in each convolutional layer\n",
        "        self.filter_size = filter_size                                          # size of filters in each convolutional layer\n",
        "        self.maxpool = maxpool                                                  # maxpooling size in each layer\n",
        "        self.conv_strides = conv_strides                                        # convolutional stride size in each layer\n",
        "        self.pool_strides = pool_strides                                        # max pool stride size in each layer\n",
        "        self.num_det = num_det                                                  # number of detectors used\n",
        "        self.batch_norm = batch_norm                                            # batch normalization on or off in each layer\n",
        "        self.by_channel = by_channel                                            # whether or not to split input up into seperate channels\n",
        "        self.weight_init = weight_init                                          # type of weight initilization to use\n",
        "        network_weights = self._create_weights()                                # initialize the network weights and biases\n",
        "        self.weights = network_weights                                          # store intialized network weights\n",
        "        self.nonlinearity = tf.nn.relu                                          # activation function to use in-between layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gS1euGakVbh",
        "colab_type": "text"
      },
      "source": [
        "### Define network archetecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyCZzCmukVB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _calc_z_mean_and_sigma(self,x,y):\n",
        "        with tf.name_scope(\"VICI_VAE_encoder\"):\n",
        "\n",
        "            # Add convolutional layers if wanted\n",
        "            if self.n_conv is not None:\n",
        "\n",
        "                # Reshape input to a multi-dimensional tensor - single channel\n",
        "                if self.by_channel == True:\n",
        "                    conv_pool = tf.reshape(y, shape=[-1, 1, y.shape[1], self.num_det])\n",
        "\n",
        "                    # Append requested number of convolutional layers to network\n",
        "                    for i in range(self.n_conv):\n",
        "                        weight_name = 'w_conv_' + str(i)\n",
        "                        bias_name = 'b_conv_' + str(i)\n",
        "                        conv_pre = tf.add(tf.nn.conv2d(conv_pool,               # Add convolutional layer\n",
        "                                          self.weights['VICI_VAE_encoder'][weight_name],\n",
        "                                          strides=[1,1,self.conv_strides[i],1],padding='SAME'),\n",
        "                                          self.weights['VICI_VAE_encoder'][bias_name])\n",
        "                        conv_post = self.nonlinearity(conv_pre)                 # Add non-linear activation function\n",
        "\n",
        "                        # Apply batch normalization if wanted\n",
        "                        if self.batch_norm == True:\n",
        "                            conv_batchNorm = tf.nn.batch_normalization(conv_post,\n",
        "                                             tf.Variable(tf.zeros([1,conv_post.shape[2],conv_post.shape[3]], \n",
        "                                             dtype=tf.float32)),tf.Variable(tf.ones([1,conv_post.shape[2],conv_post.shape[3]], \n",
        "                                             dtype=tf.float32)),None,None,0.000001)\n",
        "                            conv_dropout = tf.layers.dropout(conv_batchNorm,    # Apply dropout to layer\n",
        "                                                             rate=self.drate)\n",
        "                        else:\n",
        "                            conv_dropout = tf.layers.dropout(conv_post,         # Apply droptout to layer\n",
        "                                                             rate=self.drate)\n",
        "                        conv_pool = tf.nn.max_pool(conv_dropout,ksize=[1, 1,    # Add max pooling layer\n",
        "                                                   self.maxpool[i], 1],\n",
        "                                                   strides=[1, 1, self.pool_strides[i], 1],\n",
        "                                                   padding='SAME')\n",
        "\n",
        "                    fc = tf.concat([x,tf.reshape(conv_pool, \n",
        "                                                 [-1, int(conv_pool.shape[2]*conv_pool.shape[3])])],axis=1)\n",
        "\n",
        "                # Otherwise, reshape input into 1D tensor - multiple channels \n",
        "                if self.by_channel == False:\n",
        "                    conv_pool = tf.reshape(y, shape=[-1, y.shape[1], y.shape[2], 1])\n",
        "\n",
        "                    # Append requested number of convolutional layers to network\n",
        "                    for i in range(self.n_conv):\n",
        "                        weight_name = 'w_conv_' + str(i)\n",
        "                        bias_name = 'b_conv_' + str(i)\n",
        "                        conv_pre = tf.add(tf.nn.conv2d(conv_pool, self.weights['VICI_VAE_encoder'][weight_name],strides=[1,self.conv_strides[i],self.conv_strides[i],1],padding='SAME'),self.weights['VICI_VAE_encoder'][bias_name])\n",
        "                        conv_post = self.nonlinearity(conv_pre)\n",
        "                        if self.batch_norm == True:\n",
        "                            conv_batchNorm = tf.nn.batch_normalization(conv_post,tf.Variable(tf.zeros([conv_post.shape[1],conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),tf.Variable(tf.ones([conv_post.shape[1],conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),None,None,0.000001)\n",
        "                        conv_pool = tf.nn.max_pool(conv_batchNorm,ksize=[1, self.maxpool[i], self.maxpool[i], 1],strides=[1, self.pool_strides[i], self.pool_strides[i], 1],padding='SAME')\n",
        "\n",
        "                    fc = tf.concat([x,tf.reshape(conv_pool, [-1, int(conv_pool.shape[1]*conv_pool.shape[2]*conv_pool.shape[3])])],axis=1)\n",
        "\n",
        "            # If no convolutional filters wanted, just use fully-connected layers\n",
        "            else:\n",
        "                fc = tf.concat([x,y],axis=1)\n",
        "\n",
        "            # Append requested number of fully-connected layers\n",
        "            hidden_dropout = fc\n",
        "            for i in range(self.n_hlayers):\n",
        "                weight_name = 'w_hidden_' + str(i)\n",
        "                bias_name = 'b_hidden' + str(i)\n",
        "                hidden_pre = tf.add(tf.matmul(hidden_dropout,                   # Add fully connected layer \n",
        "                             self.weights['VICI_VAE_encoder'][weight_name]), \n",
        "                             self.weights['VICI_VAE_encoder'][bias_name])\n",
        "                hidden_post = self.nonlinearity(hidden_pre)                     # Add non-linear activation function\n",
        "\n",
        "                # Add batch normalization if requested by the user\n",
        "                if self.batch_norm == True:\n",
        "                    hidden_batchNorm = tf.nn.batch_normalization(hidden_post,tf.Variable(tf.zeros([hidden_post.shape[1]], dtype=tf.float32)),tf.Variable(tf.ones([hidden_post.shape[1]], dtype=tf.float32)),None,None,0.000001)\n",
        "                    hidden_dropout = tf.layers.dropout(hidden_batchNorm,rate=self.drate)\n",
        "                else:\n",
        "                    hidden_dropout = tf.layers.dropout(hidden_post,rate=self.drate)\n",
        "\n",
        "            # Network returns a mean (loc) and a variance (scale)\n",
        "            loc = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_VAE_encoder']['w_loc']), self.weights['VICI_VAE_encoder']['b_loc'])\n",
        "            scale = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_VAE_encoder']['w_scale']), self.weights['VICI_VAE_encoder']['b_scale'])\n",
        "\n",
        "            tf.summary.histogram('loc', loc)\n",
        "            tf.summary.histogram('scale', scale)\n",
        "            return loc, scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV47BGnko9E",
        "colab_type": "text"
      },
      "source": [
        "### Define function to sample from network predicted Gaussian's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK9FUNL3koxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _sample_from_gaussian_dist(self, num_rows, num_cols, mean, log_sigma_sq):\n",
        "        \"\"\" Function to draw samples from NN predicted Gaussians.\n",
        "        \"\"\"\n",
        "        with tf.name_scope(\"sample_in_z_space\"):                                # Just a naming mechanism which labels this operation in the graph\n",
        "            eps = tf.random_normal([num_rows, num_cols], 0, 1.,                 # Define random locations from Gaussian to sample \n",
        "                                   dtype=tf.float32)\n",
        "            sample = tf.add(mean, tf.multiply(tf.sqrt(tf.exp(log_sigma_sq)),    #  \n",
        "                                              eps))\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPkHfH3fkz1z",
        "colab_type": "text"
      },
      "source": [
        "### Define function to initialize weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSGbLjcGrbtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _create_weights(self):\n",
        "        \"\"\" Function to initialize weights of layers\n",
        "        \"\"\"\n",
        "        all_weights = collections.OrderedDict()\n",
        "        with tf.variable_scope(\"VICI_VAE_ENC\"):                                 # Just a naming mechanism (doesn't do much)\n",
        "            # Encoder \n",
        "            all_weights['VICI_VAE_encoder'] = collections.OrderedDict()         # Define dictionary to store network weights\n",
        "            \n",
        "            # Define convolutional weights\n",
        "            if self.n_conv is not None:\n",
        "                dummy = 1\n",
        "                \n",
        "                # Iterate over requested number of convolutional layers\n",
        "                for i in range(self.n_conv):\n",
        "                    weight_name = 'w_conv_' + str(i)\n",
        "                    bias_name = 'b_conv_' + str(i)\n",
        "                    # orthogonal init\n",
        "                    if self.weight_init == 'Orthogonal':\n",
        "                        shape_init = (self.filter_size[i],dummy*self.n_filters[i])\n",
        "                        initializer = tf.keras.initializers.Orthogonal()\n",
        "                        all_weights['VICI_VAE_encoder'][weight_name] = tf.Variable(tf.reshape(initializer(shape=shape_init),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    # Variance scaling\n",
        "                    if self.weight_init == 'VarianceScaling':\n",
        "                        shape_init = (self.filter_size[i],dummy*self.n_filters[i])\n",
        "                        initializer = tf.keras.initializers.VarianceScaling()\n",
        "                        all_weights['VICI_VAE_encoder'][weight_name] = tf.Variable(tf.reshape(initializer(shape=shape_init),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    # xavier initilization\n",
        "                    if self.weight_init == 'xavier':\n",
        "                        all_weights['VICI_VAE_encoder'][weight_name] = tf.Variable(tf.reshape(vae_utils.xavier_init(self.filter_size[i], dummy*self.n_filters[i]),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    all_weights['VICI_VAE_encoder'][bias_name] = tf.Variable(tf.zeros([self.n_filters[i]], dtype=tf.float32))\n",
        "                    tf.summary.histogram(weight_name, all_weights['VICI_VAE_encoder'][weight_name])\n",
        "                    tf.summary.histogram(bias_name, all_weights['VICI_VAE_encoder'][bias_name])\n",
        "                    dummy = self.n_filters[i]\n",
        "\n",
        "                # Determine correct input size to fully-connected layers after having flattened final convolutional layer\n",
        "                total_pool_stride_sum = 0\n",
        "                for j in range(len(self.maxpool)):\n",
        "                    if self.maxpool[j] != 1 and self.pool_strides[j] != 1:\n",
        "                        total_pool_stride_sum += 1\n",
        "                    else:\n",
        "                        if self.maxpool[j] != 1:\n",
        "                            total_pool_stride_sum += 1\n",
        "                        if self.pool_strides[j] != 1:\n",
        "                            total_pool_stride_sum += 1\n",
        "                    if self.conv_strides[j] != 1:\n",
        "                        total_pool_stride_sum += 1\n",
        "                if self.by_channel == True:\n",
        "                    fc_input_size = self.n_input1 + int(self.n_input2*self.n_filters[i]/(2**total_pool_stride_sum))\n",
        "                else:\n",
        "                    fc_input_size = self.n_input1 + int(self.n_input2*self.n_filters[i]/(2**total_pool_stride_sum)*2) \n",
        " \n",
        "            # If no convolutional layers, give input directly to fully-connected layers\n",
        "            else:\n",
        "                fc_input_size = self.n_input1 + self.n_input2\n",
        "\n",
        "            # Iterate over fully-connected layers\n",
        "            for i in range(self.n_hlayers):\n",
        "                weight_name = 'w_hidden_' + str(i)\n",
        "                bias_name = 'b_hidden' + str(i)\n",
        "                all_weights['VICI_VAE_encoder'][weight_name] = tf.Variable(vae_utils.xavier_init(fc_input_size, self.n_weights[i]), dtype=tf.float32)\n",
        "                all_weights['VICI_VAE_encoder'][bias_name] = tf.Variable(tf.zeros([self.n_weights[i]], dtype=tf.float32))\n",
        "                tf.summary.histogram(weight_name, all_weights['VICI_VAE_encoder'][weight_name])\n",
        "                tf.summary.histogram(bias_name, all_weights['VICI_VAE_encoder'][bias_name])\n",
        "                fc_input_size = self.n_weights[i]\n",
        "                \n",
        "            # Define weights and biases of final layer where mean and variance of Gaussians is predicted\n",
        "            all_weights['VICI_VAE_encoder']['w_loc'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_output),dtype=tf.float32)\n",
        "            all_weights['VICI_VAE_encoder']['b_loc'] = tf.Variable(tf.zeros([self.n_output], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_loc', all_weights['VICI_VAE_encoder']['w_loc'])\n",
        "            tf.summary.histogram('b_loc', all_weights['VICI_VAE_encoder']['b_loc'])\n",
        "            all_weights['VICI_VAE_encoder']['w_scale'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_output),dtype=tf.float32)\n",
        "            all_weights['VICI_VAE_encoder']['b_scale'] = tf.Variable(tf.zeros([self.n_output], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_scale', all_weights['VICI_VAE_encoder']['w_scale'])\n",
        "            tf.summary.histogram('b_scale', all_weights['VICI_VAE_encoder']['b_scale'])\n",
        "\n",
        "            all_weights['prior_param'] = collections.OrderedDict()\n",
        "        \n",
        "        return all_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJS7h46-p11s",
        "colab_type": "text"
      },
      "source": [
        "## R1 network\n",
        "Encoder network which takes as input time series only. Outputs latent space samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxf8s-12rtp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder(object):\n",
        "\n",
        "    def __init__(self, name, n_input=256, n_output=4, n_weights=2048, n_modes=2, n_hlayers=2, drate=0.2, n_filters=8, filter_size=8, maxpool=4, n_conv=2, conv_strides=1, pool_strides=1, num_det=1, batch_norm=False, by_channel=False, weight_init='xavier'):\n",
        "        \n",
        "        self.n_input = n_input\n",
        "        self.n_output = n_output\n",
        "        self.n_weights = n_weights\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.n_hlayers = n_hlayers\n",
        "        self.n_conv = n_conv\n",
        "        self.n_modes = n_modes\n",
        "        self.drate = drate\n",
        "        self.maxpool = maxpool\n",
        "        self.conv_strides = conv_strides\n",
        "        self.pool_strides = pool_strides\n",
        "        self.num_det = num_det\n",
        "        self.batch_norm = batch_norm\n",
        "        self.by_channel = by_channel\n",
        "        self.weight_init = weight_init\n",
        "\n",
        "        network_weights = self._create_weights()\n",
        "        self.weights = network_weights\n",
        "\n",
        "\n",
        "        self.nonlinearity = tf.nn.relu\n",
        "        self.nonlinearity_mean = tf.clip_by_value\n",
        "\n",
        "    def _calc_z_mean_and_sigma(self,x):\n",
        "        with tf.name_scope(\"VICI_encoder\"):\n",
        " \n",
        "            # Reshape input to a 3D tensor - single channel\n",
        "            if self.n_conv is not None:\n",
        "                if self.by_channel == True:\n",
        "                    conv_pool = tf.reshape(x, shape=[-1, 1, x.shape[1], self.num_det])\n",
        "\n",
        "                    # network for messing with kernel size\n",
        "                    for i in range(self.n_conv):\n",
        "                        weight_name = 'w_conv_' + str(i)\n",
        "                        bias_name = 'b_conv_' + str(i)\n",
        "                        conv_pre = tf.add(tf.nn.conv2d(conv_pool, self.weights['VICI_encoder'][weight_name],strides=[1,1,self.conv_strides[i],1],padding='SAME'),self.weights['VICI_encoder'][bias_name])\n",
        "                        conv_post = self.nonlinearity(conv_pre)\n",
        "                        if self.batch_norm == True:\n",
        "                            conv_batchNorm = tf.nn.batch_normalization(conv_post,tf.Variable(tf.zeros([1,conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),tf.Variable(tf.ones([1,conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),None,None,0.000001)\n",
        "                            conv_dropout = tf.layers.dropout(conv_batchNorm,rate=self.drate)\n",
        "                        else:\n",
        "                            conv_dropout = tf.layers.dropout(conv_post,rate=self.drate)\n",
        "                        conv_pool = tf.nn.max_pool(conv_dropout,ksize=[1, 1, self.maxpool[i], 1],strides=[1, 1, self.pool_strides[i], 1],padding='SAME')\n",
        "                    \n",
        "                    fc = tf.reshape(conv_pool, [-1, int(conv_pool.shape[2]*conv_pool.shape[3])])\n",
        "                if self.by_channel == False:\n",
        "                    conv_pool = tf.reshape(x, shape=[-1, x.shape[1], x.shape[2], 1])\n",
        "\n",
        "                    # network for messing with kernel size\n",
        "                    for i in range(self.n_conv):\n",
        "                        weight_name = 'w_conv_' + str(i)\n",
        "                        bias_name = 'b_conv_' + str(i)\n",
        "                        conv_pre = tf.add(tf.nn.conv2d(conv_pool, self.weights['VICI_encoder'][weight_name],strides=[1,self.conv_strides[i],self.conv_strides[i],1],padding='SAME'),self.weights['VICI_encoder'][bias_name])\n",
        "                        conv_post = self.nonlinearity(conv_pre)\n",
        "                        if self.batch_norm == True:\n",
        "                            conv_batchNorm = tf.nn.batch_normalization(conv_post,tf.Variable(tf.zeros([conv_post.shape[1],conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),tf.Variable(tf.ones([conv_post.shape[1],conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),None,None,0.000001)\n",
        "                        conv_pool = tf.nn.max_pool(conv_batchNorm,ksize=[1, self.maxpool[i], self.maxpool[i], 1],strides=[1, self.pool_strides[i], self.pool_strides[i], 1],padding='SAME')\n",
        "\n",
        "                    fc = tf.reshape(conv_pool, [-1, int(conv_pool.shape[1]*conv_pool.shape[2]*conv_pool.shape[3])])\n",
        "            else:\n",
        "                fc = x\n",
        "\n",
        "            hidden_dropout = fc\n",
        "            for i in range(self.n_hlayers):\n",
        "                weight_name = 'w_hidden_' + str(i)\n",
        "                bias_name = 'b_hidden' + str(i)\n",
        "                hidden_pre = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_encoder'][weight_name]), self.weights['VICI_encoder'][bias_name])\n",
        "                hidden_post = self.nonlinearity(hidden_pre)\n",
        "                if self.batch_norm == True:\n",
        "                    hidden_batchNorm = tf.nn.batch_normalization(hidden_post,tf.Variable(tf.zeros([hidden_post.shape[1]], dtype=tf.float32)),tf.Variable(tf.ones([hidden_post.shape[1]], dtype=tf.float32)),None,None,0.000001)\n",
        "                    hidden_dropout = tf.layers.dropout(hidden_batchNorm,rate=self.drate)\n",
        "                else:\n",
        "                    hidden_dropout = tf.layers.dropout(hidden_post,rate=self.drate)\n",
        "            loc = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_encoder']['w_loc']), self.weights['VICI_encoder']['b_loc'])\n",
        "            scale = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_encoder']['w_scale']), self.weights['VICI_encoder']['b_scale'])\n",
        "            weight = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_encoder']['w_weight']), self.weights['VICI_encoder']['b_weight']) \n",
        "\n",
        "            tf.summary.histogram('loc', loc)\n",
        "            tf.summary.histogram('scale', scale)\n",
        "            tf.summary.histogram('weight', weight)\n",
        "            return tf.reshape(loc,(-1,self.n_modes,self.n_output)), tf.reshape(scale,(-1,self.n_modes,self.n_output)), tf.reshape(weight,(-1,self.n_modes))    \n",
        "\n",
        "    def _create_weights(self):\n",
        "        all_weights = collections.OrderedDict()\n",
        "        with tf.variable_scope(\"VICI_ENC\"):            \n",
        "            all_weights['VICI_encoder'] = collections.OrderedDict()\n",
        "\n",
        "            if self.n_conv is not None:\n",
        "                dummy = 1\n",
        "                for i in range(self.n_conv):\n",
        "                    weight_name = 'w_conv_' + str(i)\n",
        "                    bias_name = 'b_conv_' + str(i)\n",
        "                    # orthogonal init\n",
        "                    if self.weight_init == 'Orthogonal':\n",
        "                        shape_init = (self.filter_size[i],dummy*self.n_filters[i])\n",
        "                        initializer = tf.keras.initializers.Orthogonal()\n",
        "                        all_weights['VICI_encoder'][weight_name] = tf.Variable(tf.reshape(initializer(shape=shape_init),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    # Variance scaling\n",
        "                    if self.weight_init == 'VarianceScaling':\n",
        "                        shape_init = (self.filter_size[i],dummy*self.n_filters[i])\n",
        "                        initializer = tf.keras.initializers.VarianceScaling()\n",
        "                        all_weights['VICI_encoder'][weight_name] = tf.Variable(tf.reshape(initializer(shape=shape_init),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    # xavier initilization\n",
        "                    if self.weight_init == 'xavier':\n",
        "                        all_weights['VICI_encoder'][weight_name] = tf.Variable(tf.reshape(vae_utils.xavier_init(self.filter_size[i], dummy*self.n_filters[i]),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    all_weights['VICI_encoder'][bias_name] = tf.Variable(tf.zeros([self.n_filters[i]], dtype=tf.float32))\n",
        "                    tf.summary.histogram(weight_name, all_weights['VICI_encoder'][weight_name])\n",
        "                    tf.summary.histogram(bias_name, all_weights['VICI_encoder'][bias_name])\n",
        "                    dummy = self.n_filters[i]\n",
        "\n",
        "                total_pool_stride_sum = 0\n",
        "                for j in range(len(self.maxpool)):\n",
        "                    if self.maxpool[j] != 1 and self.pool_strides[j] != 1:\n",
        "                        total_pool_stride_sum += 1\n",
        "                    else:\n",
        "                        if self.maxpool[j] != 1:\n",
        "                            total_pool_stride_sum += 1\n",
        "                        if self.pool_strides[j] != 1:\n",
        "                            total_pool_stride_sum += 1\n",
        "                    if self.conv_strides[j] != 1:\n",
        "                        total_pool_stride_sum += 1\n",
        "                if self.by_channel == True:\n",
        "                    fc_input_size = int(self.n_input*self.n_filters[i]/(2**total_pool_stride_sum))\n",
        "                else:\n",
        "                    fc_input_size = int((self.n_input*self.n_filters[i]/(2**total_pool_stride_sum)*2))\n",
        "            else:\n",
        "                fc_input_size = self.n_input\n",
        "\n",
        "            for i in range(self.n_hlayers):\n",
        "                weight_name = 'w_hidden_' + str(i)\n",
        "                bias_name = 'b_hidden' + str(i)\n",
        "                all_weights['VICI_encoder'][weight_name] = tf.Variable(vae_utils.xavier_init(fc_input_size, self.n_weights[i]), dtype=tf.float32)\n",
        "                all_weights['VICI_encoder'][bias_name] = tf.Variable(tf.zeros([self.n_weights[i]], dtype=tf.float32))\n",
        "                tf.summary.histogram(weight_name, all_weights['VICI_encoder'][weight_name])\n",
        "                tf.summary.histogram(bias_name, all_weights['VICI_encoder'][bias_name])\n",
        "                fc_input_size = self.n_weights[i]\n",
        "            all_weights['VICI_encoder']['w_loc'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_output*self.n_modes),dtype=tf.float32)\n",
        "            all_weights['VICI_encoder']['b_loc'] = tf.Variable(tf.zeros([self.n_output*self.n_modes], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_loc', all_weights['VICI_encoder']['w_loc'])\n",
        "            tf.summary.histogram('b_loc', all_weights['VICI_encoder']['b_loc'])\n",
        "            all_weights['VICI_encoder']['w_scale'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_output*self.n_modes),dtype=tf.float32)\n",
        "            all_weights['VICI_encoder']['b_scale'] = tf.Variable(tf.zeros([self.n_output*self.n_modes], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_scale', all_weights['VICI_encoder']['w_scale'])\n",
        "            tf.summary.histogram('b_scale', all_weights['VICI_encoder']['b_scale'])\n",
        "            all_weights['VICI_encoder']['w_weight'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_modes),dtype=tf.float32)\n",
        "            all_weights['VICI_encoder']['b_weight'] = tf.Variable(tf.zeros([self.n_modes], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_weight', all_weights['VICI_encoder']['w_weight'])\n",
        "            tf.summary.histogram('b_weight', all_weights['VICI_encoder']['b_weight'])\n",
        "\n",
        "            all_weights['prior_param'] = collections.OrderedDict()\n",
        "        \n",
        "        return all_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRrXGxH6p4cp",
        "colab_type": "text"
      },
      "source": [
        "## R2 network\n",
        "Decoder network which takes as input samples from latent space produced by q network. Outputs samples from the posterior when trained properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTjsFdBhr_8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder(object):\n",
        "\n",
        "    def __init__(self, name, wrap_mask, nowrap_mask, n_input1=4, n_input2=256, n_output=3, n_weights=2048, n_hlayers=2, drate=0.2, n_filters=8, filter_size=8, maxpool=4, n_conv=2, conv_strides=1, pool_strides=1, num_det=1, batch_norm=False,by_channel=False, weight_init='xavier'):\n",
        "        \n",
        "        self.n_input1 = n_input1                    # actually the output size\n",
        "        self.n_input2 = n_input2                    # actually the output size\n",
        "        self.n_output = n_output                  # the input data size\n",
        "        self.n_weights = n_weights                # the number of weights were layer\n",
        "        self.n_hlayers = n_hlayers\n",
        "        self.n_conv = n_conv\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.maxpool = maxpool\n",
        "        self.conv_strides = conv_strides\n",
        "        self.pool_strides = pool_strides\n",
        "        self.name = name                          # the name of the network\n",
        "        self.drate = drate                        # dropout rate\n",
        "        self.wrap_mask = wrap_mask                # mask identifying wrapped indices\n",
        "        self.nowrap_mask = nowrap_mask            # mask identifying non-wrapped indices\n",
        "        self.num_det = num_det\n",
        "        self.batch_norm = batch_norm\n",
        "        self.by_channel = by_channel\n",
        "        self.weight_init = weight_init \n",
        "\n",
        "        network_weights = self._create_weights()\n",
        "        self.weights = network_weights\n",
        "\n",
        "        self.nonlinear_loc_nowrap = tf.sigmoid    # activation for non-wrapped location params\n",
        "        self.nonlinear_loc_wrap = tf.sigmoid      # activation for wrapped location params\n",
        "        self.nonlinear_scale_nowrap = tf.identity # activation for non-wrapped scale params\n",
        "        self.nonlinear_scale_wrap = tf.nn.relu    # activation for wrapped scale params  \n",
        "        self.nonlinearity = tf.nn.relu            # activation between hidden layers\n",
        "\n",
        "    def calc_reconstruction(self, z, y):\n",
        "        with tf.name_scope(\"VICI_decoder\"):\n",
        "\n",
        "            # Reshape input to a 3D tensor - single channel\n",
        "            if self.n_conv is not None:\n",
        "                if self.by_channel == True:\n",
        "                    conv_pool = tf.reshape(y, shape=[-1, 1, y.shape[1], self.num_det])\n",
        "                    for i in range(self.n_conv):            \n",
        "                        weight_name = 'w_conv_' + str(i)\n",
        "                        bias_name = 'b_conv_' + str(i)\n",
        "                        conv_pre = tf.add(tf.nn.conv2d(conv_pool, self.weights['VICI_decoder'][weight_name],strides=[1,1,self.conv_strides[i],1],padding='SAME'),self.weights['VICI_decoder'][bias_name])\n",
        "                        conv_post = self.nonlinearity(conv_pre)\n",
        "                        if self.batch_norm == True:\n",
        "                            conv_batchNorm = tf.nn.batch_normalization(conv_post,tf.Variable(tf.zeros([1,conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),tf.Variable(tf.ones([1,conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),None,None,0.000001)\n",
        "                            conv_dropout = tf.layers.dropout(conv_batchNorm,rate=self.drate)\n",
        "                        else:\n",
        "                            conv_dropout = tf.layers.dropout(conv_post,rate=self.drate)\n",
        "                        conv_pool = tf.nn.max_pool(conv_dropout,ksize=[1, 1, self.maxpool[i], 1],strides=[1, 1, self.pool_strides[i], 1],padding='SAME')\n",
        "\n",
        "                    fc = tf.concat([z,tf.reshape(conv_pool, [-1, int(conv_pool.shape[2]*conv_pool.shape[3])])],axis=1)            \n",
        "                if self.by_channel == False:\n",
        "                    conv_pool = tf.reshape(y, shape=[-1, y.shape[1], y.shape[2], 1])\n",
        "                    for i in range(self.n_conv):\n",
        "                        weight_name = 'w_conv_' + str(i)\n",
        "                        bias_name = 'b_conv_' + str(i)\n",
        "                        conv_pre = tf.add(tf.nn.conv2d(conv_pool, self.weights['VICI_decoder'][weight_name],strides=[1,self.conv_strides[i],self.conv_strides[i],1],padding='SAME'),self.weights['VICI_decoder'][bias_name])\n",
        "                        conv_post = self.nonlinearity(conv_pre)\n",
        "                        if self.batch_norm == True:\n",
        "                            conv_batchNorm = tf.nn.batch_normalization(conv_post,tf.Variable(tf.zeros([conv_post.shape[1],conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),tf.Variable(tf.ones([conv_post.shape[1],conv_post.shape[2],conv_post.shape[3]], dtype=tf.float32)),None,None,0.000001)\n",
        "                        conv_pool = tf.nn.max_pool(conv_batchNorm,ksize=[1, self.maxpool[i], self.maxpool[i], 1],strides=[1, self.pool_strides[i], self.pool_strides[i], 1],padding='SAME')\n",
        "\n",
        "                    fc = tf.concat([z,tf.reshape(conv_pool, [-1, int(conv_pool.shape[1]*conv_pool.shape[2]*conv_pool.shape[3])])],axis=1)\n",
        "            else:\n",
        "                fc = tf.concat([z,y],axis=1)\n",
        "\n",
        "            hidden_dropout = fc\n",
        "            for i in range(self.n_hlayers):\n",
        "                weight_name = 'w_hidden_' + str(i)\n",
        "                bias_name = 'b_hidden' + str(i)\n",
        "                hidden_pre = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_decoder'][weight_name]), self.weights['VICI_decoder'][bias_name])\n",
        "                hidden_post = self.nonlinearity(hidden_pre)\n",
        "                if self.batch_norm == True:\n",
        "                    hidden_batchNorm = tf.nn.batch_normalization(hidden_post,tf.Variable(tf.zeros([hidden_post.shape[1]], dtype=tf.float32)),tf.Variable(tf.ones([hidden_post.shape[1]], dtype=tf.float32)),None,None,0.000001)\n",
        "                    hidden_dropout = tf.layers.dropout(hidden_batchNorm,rate=self.drate)\n",
        "                else:\n",
        "                    hidden_dropout = tf.layers.dropout(hidden_post,rate=self.drate)\n",
        "            loc_all = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_decoder']['w_loc']), self.weights['VICI_decoder']['b_loc'])\n",
        "            scale_all = tf.add(tf.matmul(hidden_dropout, self.weights['VICI_decoder']['w_scale']), self.weights['VICI_decoder']['b_scale'])\n",
        "\n",
        "            # split up the output into non-wrapped and wrapped params and apply appropriate activation\n",
        "            loc_nowrap = self.nonlinear_loc_nowrap(tf.boolean_mask(loc_all,self.nowrap_mask,axis=1))\n",
        "            scale_nowrap = self.nonlinear_scale_nowrap(tf.boolean_mask(scale_all,self.nowrap_mask,axis=1))\n",
        "            if np.sum(self.wrap_mask)>0:\n",
        "                loc_wrap = self.nonlinear_loc_wrap(tf.boolean_mask(loc_all,self.wrap_mask,axis=1))\n",
        "                scale_wrap = -1.0*self.nonlinear_scale_wrap(tf.boolean_mask(scale_all,self.wrap_mask,axis=1))\n",
        "                return loc_nowrap, scale_nowrap, loc_wrap, scale_wrap\n",
        "            else:\n",
        "                return loc_nowrap, scale_nowrap\n",
        "\n",
        "    def _create_weights(self):\n",
        "        all_weights = collections.OrderedDict()\n",
        "\n",
        "        # Decoder\n",
        "        with tf.variable_scope(\"VICI_DEC\"):\n",
        "            all_weights['VICI_decoder'] = collections.OrderedDict()\n",
        "            \n",
        "            if self.n_conv is not None:\n",
        "                dummy = 1\n",
        "                for i in range(self.n_conv):\n",
        "                    weight_name = 'w_conv_' + str(i)\n",
        "                    bias_name = 'b_conv_' + str(i)\n",
        "                    # orthogonal init\n",
        "                    if self.weight_init == 'Orthogonal':\n",
        "                        shape_init = (self.filter_size[i],dummy*self.n_filters[i])\n",
        "                        initializer = tf.keras.initializers.Orthogonal()\n",
        "                        all_weights['VICI_decoder'][weight_name] = tf.Variable(tf.reshape(initializer(shape=shape_init),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    # Variance scaling\n",
        "                    if self.weight_init == 'VarianceScaling':\n",
        "                        shape_init = (self.filter_size[i],dummy*self.n_filters[i])\n",
        "                        initializer = tf.keras.initializers.VarianceScaling()\n",
        "                        all_weights['VICI_decoder'][weight_name] = tf.Variable(tf.reshape(initializer(shape=shape_init),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    # xavier initilization\n",
        "                    if self.weight_init == 'xavier':\n",
        "                        all_weights['VICI_decoder'][weight_name] = tf.Variable(tf.reshape(vae_utils.xavier_init(self.filter_size[i], dummy*self.n_filters[i]),[self.filter_size[i], 1, dummy, self.n_filters[i]]), dtype=tf.float32)\n",
        "                    all_weights['VICI_decoder'][bias_name] = tf.Variable(tf.zeros([self.n_filters[i]], dtype=tf.float32))\n",
        "                    tf.summary.histogram(weight_name, all_weights['VICI_decoder'][weight_name])\n",
        "                    tf.summary.histogram(bias_name, all_weights['VICI_decoder'][bias_name])\n",
        "                    dummy = self.n_filters[i]\n",
        "\n",
        "                total_pool_stride_sum = 0\n",
        "                for j in range(len(self.maxpool)):\n",
        "                    if self.maxpool[j] != 1 and self.pool_strides[j] != 1:\n",
        "                        total_pool_stride_sum += 1\n",
        "                    else:\n",
        "                        if self.maxpool[j] != 1:\n",
        "                            total_pool_stride_sum += 1\n",
        "                        if self.pool_strides[j] != 1:\n",
        "                            total_pool_stride_sum += 1\n",
        "                    if self.conv_strides[j] != 1:\n",
        "                        total_pool_stride_sum += 1\n",
        "                if self.by_channel == True:\n",
        "                    fc_input_size = self.n_input1 + int(self.n_input2*self.n_filters[i]/(2**total_pool_stride_sum))\n",
        "                else:\n",
        "                    fc_input_size = self.n_input1 + int(self.n_input2*self.n_filters[i]/(2**total_pool_stride_sum)*2)\n",
        "            else:\n",
        "                fc_input_size = self.n_input1 + self.n_input2\n",
        "\n",
        "            for i in range(self.n_hlayers):\n",
        "                weight_name = 'w_hidden_' + str(i)\n",
        "                bias_name = 'b_hidden' + str(i)\n",
        "                all_weights['VICI_decoder'][weight_name] = tf.Variable(vae_utils.xavier_init(fc_input_size, self.n_weights[i]), dtype=tf.float32)\n",
        "                all_weights['VICI_decoder'][bias_name] = tf.Variable(tf.zeros([self.n_weights[i]], dtype=tf.float32))\n",
        "                tf.summary.histogram(weight_name, all_weights['VICI_decoder'][weight_name])\n",
        "                tf.summary.histogram(bias_name, all_weights['VICI_decoder'][bias_name])\n",
        "                fc_input_size = self.n_weights[i]\n",
        "            all_weights['VICI_decoder']['w_loc'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_output),dtype=tf.float32)\n",
        "            all_weights['VICI_decoder']['b_loc'] = tf.Variable(tf.zeros([self.n_output], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_loc', all_weights['VICI_decoder']['w_loc'])\n",
        "            tf.summary.histogram('b_loc', all_weights['VICI_decoder']['b_loc'])\n",
        "            all_weights['VICI_decoder']['w_scale'] = tf.Variable(vae_utils.xavier_init(self.n_weights[-1], self.n_output),dtype=tf.float32)\n",
        "            all_weights['VICI_decoder']['b_scale'] = tf.Variable(tf.zeros([self.n_output], dtype=tf.float32), dtype=tf.float32)\n",
        "            tf.summary.histogram('w_scale', all_weights['VICI_decoder']['w_scale'])\n",
        "            tf.summary.histogram('b_scale', all_weights['VICI_decoder']['b_scale'])\n",
        "            \n",
        "            all_weights['prior_param'] = collections.OrderedDict()\n",
        "        \n",
        "        return all_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T4N8EJLXgu-",
        "colab_type": "text"
      },
      "source": [
        "# Further Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maLy6ASgXkQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}